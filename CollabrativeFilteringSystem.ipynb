{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjS+100U21l+2vT83i3mY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulusshewamre/Content-Collab-Hybrid-recsys/blob/main/CollabrativeFilteringSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "6HGZG6oofuCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the neccesary datas and data retriveing functions\n"
      ],
      "metadata": {
        "id": "2KeJmfrJiANl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "doc = files.upload()  # Upload kaggle.json here"
      ],
      "metadata": {
        "id": "F9hZdjYjDHc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "bdca0e04-2310-4834-f354-c04671db8609",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be7735dc-fc83-4ea1-a112-7e132faabf5d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be7735dc-fc83-4ea1-a112-7e132faabf5d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.zip to data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")  # this will create a folder \"data\" in Colab"
      ],
      "metadata": {
        "id": "HUK85mJ3xZwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"data/data\"  # inside Colab environment"
      ],
      "metadata": {
        "id": "4UGwMla7xZtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
        "dfs = {os.path.basename(f).split(\".\")[0]: pd.read_csv(f) for f in csv_files}\n",
        "\n",
        "print(dfs.keys())  # lists all CSV filenames without \".csv\""
      ],
      "metadata": {
        "id": "OBxWCDorSNbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f288f74-0cc9-4657-89cb-52da98fe5116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['small_movie_list', 'small_movies_R', 'small_movies_b', 'small_movies_Y', 'small_movies_W', 'small_movies_X'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload only 'small_movies_b' correctly\n",
        "dfs['small_movies_b'] = pd.read_csv('./data/data/small_movies_b.csv', header=None)\n",
        "\n",
        "# Convert to NumPy and reshape dynamically\n",
        "movies_b = dfs['small_movies_b'].to_numpy().reshape(1, -1)"
      ],
      "metadata": {
        "id": "t5MVdOkt_bbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = list(dfs.values())\n",
        "\n",
        "# Access each file by index\n",
        "movie_list = dataframes[0].to_numpy()\n",
        "movies_R = dataframes[1].to_numpy()\n",
        "movies_Y = dataframes[3].to_numpy()\n",
        "movies_W = dataframes[4].to_numpy()\n",
        "movies_X = dataframes[5].to_numpy()"
      ],
      "metadata": {
        "id": "VFbHcnxntaYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_precalc_params_small():\n",
        "    \"\"\"\n",
        "    Load precomputed parameters from the already loaded CSV DataFrames in `dfs`.\n",
        "    Assumes dfs contains:\n",
        "    'movies_X', 'movies_W', 'movies_b', etc.\n",
        "    \"\"\"\n",
        "\n",
        "    # Access DataFrames by name from dfs\n",
        "    X = movies_X\n",
        "    W = movies_W\n",
        "    b = movies_b\n",
        "\n",
        "    num_movies, num_features = X.shape\n",
        "    num_users, _ = W.shape\n",
        "\n",
        "    return X, W, b, num_movies, num_features, num_users\n"
      ],
      "metadata": {
        "id": "1DijMjQS2ePv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ratings_small():\n",
        "    \"\"\"\n",
        "    Load Y and R matrices from the preloaded CSV DataFrames in `dfs`.\n",
        "    Assumes dfs contains:\n",
        "    'movies_Y' and 'movies_R'.\n",
        "    \"\"\"\n",
        "\n",
        "    Y = movies_Y\n",
        "    R = movies_R\n",
        "\n",
        "    return Y, R\n"
      ],
      "metadata": {
        "id": "50t7hSwu4Bh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
        "Y, R = load_ratings_small()\n",
        "\n",
        "print(\"Y\", Y.shape, \"R\", R.shape)\n",
        "print(\"X\", X.shape)\n",
        "print(\"W\", W.shape)\n",
        "print(\"b\", b.shape)\n",
        "print(\"num_features\", num_features)\n",
        "print(\"num_movies\",   num_movies)\n",
        "print(\"num_users\",    num_users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPNtws4u1RWk",
        "outputId": "7d13716c-f8b5-4e95-e113-f2c24b46e84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y (4777, 443) R (4777, 443)\n",
            "X (4777, 10)\n",
            "W (442, 10)\n",
            "b (1, 443)\n",
            "num_features 10\n",
            "num_movies 4777\n",
            "num_users 442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  From the matrix, we can compute statistics like average rating.\n",
        "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
        "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhiwgz-t4Dxx",
        "outputId": "10a4d378-747a-422a-cb29-d1ec99d5ce88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average rating for movie 1 : 3.250 / 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
        "    \"\"\"\n",
        "    Returns the cost for the content-based filtering\n",
        "    Args:\n",
        "      X (ndarray (num_movies,num_features)): matrix of item features\n",
        "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
        "      b (ndarray (1, num_users)            : vector of user parameters\n",
        "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
        "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
        "      lambda_ (float): regularization parameter\n",
        "    Returns:\n",
        "      J (float) : Cost\n",
        "    \"\"\"\n",
        "    nm, nu = Y.shape\n",
        "    J = 0\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    for j in range(nu):\n",
        "        w = W[j,:]\n",
        "        b_j = b[0,j]\n",
        "        for i in range(nm):\n",
        "            x = X[i,:]\n",
        "            y = Y[i,j]\n",
        "            r = R[i,j]\n",
        "            J += np.square(r * (np.dot(w,x) + b_j - y ) )\n",
        "    J = J/2\n",
        "    J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return J"
      ],
      "metadata": {
        "id": "2DhjmZqb4_8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the data set size so that this runs faster\n",
        "num_users_r = 4\n",
        "num_movies_r = 5\n",
        "num_features_r = 3\n",
        "\n",
        "X_r = X[:num_movies_r, :num_features_r]\n",
        "W_r = W[:num_users_r,  :num_features_r]\n",
        "b_r = b[0, :num_users_r].reshape(1,-1)\n",
        "Y_r = Y[:num_movies_r, :num_users_r]\n",
        "R_r = R[:num_movies_r, :num_users_r]\n",
        "\n",
        "# Evaluate cost function\n",
        "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\n",
        "print(f\"Cost: {J:0.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM0Dyqxk5JSw",
        "outputId": "1c3e0666-f639-4244-8740-9a0ddda3552b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 11.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate cost function with regularization\n",
        "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
        "print(f\"Cost (with regularization): {J:0.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuDhnKDr5Mlv",
        "outputId": "3b019b30-0aeb-4ead-d3a1-e7fe31ad925f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost (with regularization): 24.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectoriazation method for faster calculations"
      ],
      "metadata": {
        "id": "ZCI2TxCzAHYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
        "    \"\"\"\n",
        "    Returns the cost for the content-based filtering\n",
        "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
        "    Args:\n",
        "      X (ndarray (num_movies,num_features)): matrix of item features\n",
        "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
        "      b (ndarray (1, num_users)            : vector of user parameters\n",
        "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
        "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
        "      lambda_ (float): regularization parameter\n",
        "    Returns:\n",
        "      J (float) : Cost\n",
        "    \"\"\"\n",
        "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
        "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
        "    return J"
      ],
      "metadata": {
        "id": "koJjwswFAGLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate cost function\n",
        "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 0);\n",
        "print(f\"Cost: {J:0.2f}\")\n",
        "\n",
        "# Evaluate cost function with regularization\n",
        "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
        "print(f\"Cost (with regularization): {J:0.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW-kRdkM_7cm",
        "outputId": "eb2556cc-cd3c-4a10-aa8a-17798a7f26be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 11.66\n",
            "Cost (with regularization): 24.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_Movie_List_pd():\n",
        "    \"\"\"\n",
        "    Returns a list of movie titles and the corresponding DataFrame,\n",
        "    using the preloaded DataFrame from dfs.\n",
        "    Assumes dfs contains 'small_movie_list'.\n",
        "    \"\"\"\n",
        "\n",
        "    # Access the DataFrame from dfs\n",
        "    df = dfs['small_movie_list']\n",
        "\n",
        "    # Convert the \"title\" column to a list\n",
        "    mlist = df[\"title\"].to_list()\n",
        "\n",
        "    return mlist, df\n"
      ],
      "metadata": {
        "id": "qZy4qtFAAVTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make initial Prediction without trained model"
      ],
      "metadata": {
        "id": "JB7Fo91vhssy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movieList, movieList_df = load_Movie_List_pd()\n",
        "\n",
        "my_ratings = np.zeros(num_movies)          #  Initialize my ratings\n",
        "\n",
        "# Check the file small_movie_list.csv for id of each movie in our dataset\n",
        "# For example, Toy Story 3 (2010) has ID 2700, so to rate it \"5\", you can set\n",
        "my_ratings[2700] = 5\n",
        "\n",
        "#Or suppose you did not enjoy Persuasion (2007), you can set\n",
        "my_ratings[2609] = 2;\n",
        "\n",
        "# We have selected a few movies we liked / did not like and the ratings we\n",
        "# gave are as follows:\n",
        "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
        "my_ratings[246]  = 5   # Shrek (2001)\n",
        "my_ratings[2716] = 3   # Inception\n",
        "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
        "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
        "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
        "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
        "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
        "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
        "my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)\n",
        "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
        "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
        "\n",
        "print('\\nNew user ratings:\\n')\n",
        "for i in range(len(my_ratings)):\n",
        "    if my_ratings[i] > 0 :\n",
        "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLL6C3I4AL_N",
        "outputId": "5edd11ef-e440-4feb-c075-da2a635aad2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New user ratings:\n",
            "\n",
            "Rated 5.0 for  Shrek (2001)\n",
            "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
            "Rated 2.0 for  Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
            "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
            "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
            "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
            "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
            "Rated 5.0 for  Incredibles, The (2004)\n",
            "Rated 2.0 for  Persuasion (2007)\n",
            "Rated 5.0 for  Toy Story 3 (2010)\n",
            "Rated 3.0 for  Inception (2010)\n",
            "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
            "Rated 1.0 for  Nothing to Declare (Rien à déclarer) (2010)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the ratings"
      ],
      "metadata": {
        "id": "gaR6ewtagoOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalizeRatings(Y, R):\n",
        "    \"\"\"\n",
        "    Normalize movie ratings by subtracting the mean rating for each movie.\n",
        "\n",
        "    Parameters:\n",
        "        Y : numpy array of shape (num_movies, num_users)\n",
        "            Ratings matrix\n",
        "        R : numpy array of same shape as Y\n",
        "            Indicator matrix where R[i,j] = 1 if movie i was rated by user j\n",
        "\n",
        "    Returns:\n",
        "        Ynorm : numpy array of same shape as Y\n",
        "            Normalized ratings (mean of each movie subtracted, unrated entries remain 0)\n",
        "        Ymean : numpy array of shape (num_movies, 1)\n",
        "            Mean rating for each movie\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute mean rating for each movie, ignoring unrated entries\n",
        "    # Add a small epsilon to avoid division by zero\n",
        "    Ymean = (np.sum(Y * R, axis=1) / (np.sum(R, axis=1) + 1e-12)).reshape(-1, 1)\n",
        "\n",
        "    # Subtract the mean rating from all rated entries\n",
        "    Ynorm = Y - np.multiply(Ymean, R)\n",
        "\n",
        "    return Ynorm, Ymean\n"
      ],
      "metadata": {
        "id": "mqCo4xHBBt3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Neural network find the optimal parameters (Gradient Descent)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QFkhqr2Ng4tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload ratings\n",
        "Y, R = load_ratings_small()\n",
        "\n",
        "# Add new user ratings to Y\n",
        "Y = np.c_[my_ratings, Y]\n",
        "\n",
        "# Add new user indicator matrix to R\n",
        "R = np.c_[(my_ratings != 0).astype(int), R]\n",
        "\n",
        "# Normalize the Dataset\n",
        "Ynorm, Ymean = normalizeRatings(Y, R)"
      ],
      "metadata": {
        "id": "OAA8_b1hAmq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Useful Values\n",
        "num_movies, num_users = Y.shape\n",
        "num_features = 100\n",
        "\n",
        "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
        "tf.random.set_seed(1234) # for consistent results\n",
        "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
        "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
        "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
        "\n",
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
      ],
      "metadata": {
        "id": "jU2mhiLWBs2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 200\n",
        "lambda_ = 1\n",
        "for iter in range(iterations):\n",
        "    # Use TensorFlow’s GradientTape\n",
        "    # to record the operations used to compute the cost\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        # Compute the cost (forward pass included in cost)\n",
        "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
        "\n",
        "    # Use the gradient tape to automatically retrieve\n",
        "    # the gradients of the trainable variables with respect to the loss\n",
        "    grads = tape.gradient( cost_value, [X,W,b] )\n",
        "\n",
        "    # Run one step of gradient descent by updating\n",
        "    # the value of the variables to minimize the loss.\n",
        "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
        "\n",
        "    # Log periodically.\n",
        "    if iter % 20 == 0:\n",
        "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2Pnm6QRB9Lo",
        "outputId": "227382e8-baab-4df3-ed40-5fc2c4e0440a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss at iteration 0: 2291969.9\n",
            "Training loss at iteration 20: 134129.7\n",
            "Training loss at iteration 40: 50764.9\n",
            "Training loss at iteration 60: 24024.3\n",
            "Training loss at iteration 80: 13321.8\n",
            "Training loss at iteration 100: 8307.8\n",
            "Training loss at iteration 120: 5688.4\n",
            "Training loss at iteration 140: 4224.1\n",
            "Training loss at iteration 160: 3367.9\n",
            "Training loss at iteration 180: 2849.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions with the optimal parameters recived from model"
      ],
      "metadata": {
        "id": "atdCWwmGhJKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using trained weights and biases\n",
        "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
        "\n",
        "#restore the mean\n",
        "pm = p + Ymean\n",
        "\n",
        "my_predictions = pm[:,0]\n",
        "\n",
        "# sort predictions\n",
        "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
        "\n",
        "for i in range(17):\n",
        "    j = ix[i]\n",
        "    if j not in my_rated:\n",
        "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
        "\n",
        "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
        "for i in range(len(my_ratings)):\n",
        "    if my_ratings[i] > 0:\n",
        "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfkhuCpiCBQC",
        "outputId": "fd52f64d-be03-4fc0-e542-79559215d081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting rating 5.63 for movie Purge: Anarchy, The (2014)\n",
            "Predicting rating 5.23 for movie Ginger Snaps: Unleashed (2004)\n",
            "Predicting rating 5.20 for movie I Heart Huckabees (2004)\n",
            "Predicting rating 5.20 for movie Igby Goes Down (2002)\n",
            "Predicting rating 5.18 for movie Promised Land (2012)\n",
            "Predicting rating 5.18 for movie Last Knights (2015)\n",
            "Predicting rating 5.18 for movie Whole Nine Yards, The (2000)\n",
            "Predicting rating 5.18 for movie Dog Days (Hundstage) (2001)\n",
            "Predicting rating 5.18 for movie Che: Part One (2008)\n",
            "Predicting rating 5.18 for movie Day the Earth Stood Still, The (2008)\n",
            "Predicting rating 5.18 for movie Jeff Ross Roasts Criminals: Live at Brazos County Jail (2015)\n",
            "Predicting rating 5.18 for movie Kicking Off (2016)\n",
            "Predicting rating 5.18 for movie Secret Ballot (Raye makhfi) (2001)\n",
            "Predicting rating 5.18 for movie Into the Grizzly Maze (2015)\n",
            "Predicting rating 5.18 for movie Brave (2012)\n",
            "Predicting rating 5.18 for movie The Death of Stalin (2017)\n",
            "Predicting rating 5.18 for movie Last Exorcism, The (2010)\n",
            "\n",
            "\n",
            "Original vs Predicted ratings:\n",
            "\n",
            "Original 5.0, Predicted 4.98 for Shrek (2001)\n",
            "Original 5.0, Predicted 4.60 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
            "Original 2.0, Predicted 2.07 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
            "Original 5.0, Predicted 4.99 for Harry Potter and the Chamber of Secrets (2002)\n",
            "Original 5.0, Predicted 4.77 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
            "Original 5.0, Predicted 4.76 for Lord of the Rings: The Return of the King, The (2003)\n",
            "Original 3.0, Predicted 3.08 for Eternal Sunshine of the Spotless Mind (2004)\n",
            "Original 5.0, Predicted 4.81 for Incredibles, The (2004)\n",
            "Original 2.0, Predicted 2.44 for Persuasion (2007)\n",
            "Original 5.0, Predicted 4.80 for Toy Story 3 (2010)\n",
            "Original 3.0, Predicted 3.09 for Inception (2010)\n",
            "Original 1.0, Predicted 1.46 for Louis Theroux: Law & Disorder (2008)\n",
            "Original 1.0, Predicted 1.15 for Nothing to Declare (Rien à déclarer) (2010)\n"
          ]
        }
      ]
    }
  ]
}